{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5760c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Bước 1: Tải dữ liệu\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Chỉ lấy 2 lớp để test phân loại nhị phân (cho LogisticRegression dễ hiểu)\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "\n",
    "# Bước 2: Tách train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Bước 3: Tạo pipeline\n",
    "steps = [\n",
    "    ('scaler', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('clf', LogisticRegression())\n",
    "]\n",
    "model = Pipeline(steps=steps)\n",
    "\n",
    "# Bước 4: Huấn luyện\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Bước 5: Dự đoán và đánh giá\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Predictions:\", y_pred)\n",
    "print(\"Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688032eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patience': [5, 10],\n",
       " 'min_delta': [0.001],\n",
       " 'epochs': [30, 50],\n",
       " 'learning_rate': [0.001, 0.01],\n",
       " 'layer0__name': ['DenseBatchNormalizationDropoutTuner'],\n",
       " 'layer0__dropout_rate': [0.5],\n",
       " 'layer0__start_units': [16],\n",
       " 'layer0__num_layers': [1, 2, 3, 4, 5],\n",
       " 'layer1__name': ['DenseBatchNormalizationTuner'],\n",
       " 'layer1__start_units': [8],\n",
       " 'layer1__num_layers': [1, 2, 3, 4, 5]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = param_dict.pop('layers') \n",
    "\n",
    "def handle_1item(a, i):\n",
    "    a_keys = [f\"layer{i}__{key}\" for key in a.keys()]\n",
    "    a = dict(zip(a_keys, a.values()))\n",
    "    return a\n",
    "\n",
    "\n",
    "a = [handle_1item(item, i) for i, item in enumerate(a)  ]\n",
    "\n",
    "import itertools\n",
    "b_keys = list(itertools.chain(*[list(item.keys()) for item in a]) )\n",
    "b_values = list(itertools.chain(*[list(item.values()) for item in a])) \n",
    "\n",
    "b = dict(zip(b_keys, b_values))\n",
    "\n",
    "\n",
    "c_keys = list(param_dict.keys()) + list(b.keys())\n",
    "c_values = list(param_dict.values()) + list(b.values())\n",
    "c_values = [item if isinstance(item, list) else [item] for item in c_values]\n",
    "\n",
    "c = dict(zip(c_keys, c_values))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b96fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patience': [5, 10],\n",
       " 'min_delta': [0.001],\n",
       " 'epochs': [30, 50],\n",
       " 'learning_rate': [0.001, 0.01],\n",
       " 'layer0__name': ['DenseBatchNormalizationDropoutTuner'],\n",
       " 'layer0__dropout_rate': [0.5],\n",
       " 'layer0__start_units': [16],\n",
       " 'layer0__num_layers': [1, 2, 3, 4, 5],\n",
       " 'layer1__name': ['DenseBatchNormalizationTuner'],\n",
       " 'layer1__start_units': [8],\n",
       " 'layer1__num_layers': [1, 2, 3, 4, 5]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def add_layer_text_to_key(a, i):\n",
    "    a_keys = [f\"layer{i}__{key}\" for key in a.keys()]\n",
    "    a = dict(zip(a_keys, a.values()))\n",
    "    return a\n",
    "\n",
    "def get_list_param(param_dict):\n",
    "    # Loại bỏ key\n",
    "    list_layers = param_dict.pop(\"layers\")\n",
    "\n",
    "    # Thêm tiền tố layer vào mỗi key trong list_layers\n",
    "    list_layers = [\n",
    "        add_layer_text_to_key(layer, i) for i, layer in enumerate(list_layers)\n",
    "    ]\n",
    "\n",
    "    # Tạo list_layers mới\n",
    "    list_layers_keys = list(\n",
    "        itertools.chain(*[list(item.keys()) for item in list_layers])\n",
    "    )\n",
    "    list_layers_values = list(\n",
    "        itertools.chain(*[list(item.values()) for item in list_layers])\n",
    "    )\n",
    "    list_layers = dict(zip(list_layers_keys, list_layers_values))\n",
    "\n",
    "    # Tổng hợp tạo ra param_dict\n",
    "    param_dict_keys = list(param_dict.keys()) + list(list_layers.keys())\n",
    "    param_dict_values = list(param_dict.values()) + list(list_layers.values())\n",
    "    param_dict_values = [\n",
    "        item if isinstance(item, list) else [item] for item in param_dict_values\n",
    "    ]\n",
    "\n",
    "    param_dict = dict(zip(param_dict_keys, param_dict_values))\n",
    "\n",
    "    return param_dict\n",
    "\n",
    "param_dict = {\n",
    "    \"patience\": [5, 10], \n",
    "    \"min_delta\": [0.001], \n",
    "    \"epochs\": [30, 50], \n",
    "    \"learning_rate\": [0.001, 0.01], \n",
    "    \"layers\": [\n",
    "        {\n",
    "            \"name\": 'DenseBatchNormalizationDropoutTuner', \n",
    "            \"dropout_rate\": 0.5,\n",
    "            \"start_units\": 16, \n",
    "            \"num_layers\": [1,2,3,4,5], \n",
    "        }, \n",
    "        {\n",
    "            \"name\": 'DenseBatchNormalizationTuner', \n",
    "            \"start_units\": 8, \n",
    "            \"num_layers\": [1,2,3,4,5], \n",
    "           \n",
    "        }, \n",
    "    ]\n",
    "}\n",
    "\n",
    "get_list_param(param_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7456fce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patience': 10,\n",
       " 'min_delta': 0.001,\n",
       " 'learning_rate': 0.001,\n",
       " 'layer2__start_units_A': 8,\n",
       " 'layer2__num_layers_A': 1,\n",
       " 'layer2__name': 'A',\n",
       " 'layer2__drop_A': 100,\n",
       " 'layer1__start_units': 8,\n",
       " 'layer1__num_layers': 2,\n",
       " 'layer1__name': 'DenseBatchNormalizationTuner',\n",
       " 'layer0__start_units': 16,\n",
       " 'layer0__num_layers': 2,\n",
       " 'layer0__name': 'DenseBatchNormalizationDropoutTuner',\n",
       " 'layer0__dropout_rate': 0.5,\n",
       " 'epochs': 30}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "param_list = list(ParameterSampler(c, n_iter=10, random_state=42))\n",
    "param_list[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be8d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patience': [5, 10],\n",
       " 'min_delta': [0.001],\n",
       " 'epochs': [30, 50],\n",
       " 'learning_rate': [0.001, 0.01],\n",
       " 'layer0_none': [None],\n",
       " 'layer1__name': ['DenseBatchNormalizationTuner'],\n",
       " 'layer1__start_units': [16],\n",
       " 'layer1__list_num_layers': [1, 2, 3, 4, 5]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {\n",
    "    \"patience\": [5, 10], \n",
    "    \"min_delta\": [0.001], \n",
    "    \"epochs\": [30, 50], \n",
    "    \"learning_rate\": [0.001, 0.01], \n",
    "    \"layers\": [\n",
    "        {\n",
    "            # \"name\": 'DenseBatchNormalizationDropoutTuner', \n",
    "            # \"dropout_rate\": 0.5,\n",
    "            # \"start_units\": 128, \n",
    "            # \"list_num_layers\": [1,2,3,4,5], \n",
    "        }, \n",
    "        {\n",
    "            \"name\": 'DenseBatchNormalizationTuner', \n",
    "            \"start_units\": 16, \n",
    "            \"list_num_layers\": [1,2,3,4,5], \n",
    "           \n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "class ListParamCreator:\n",
    "    def __init__(self, param_dict, num_models):\n",
    "        \"\"\"Tạo ra danh sách các tham số phục vụ cho model training, cấu trúc của param_dict phải là như sau: <br>\n",
    "        ```\n",
    "        param_dict = {\n",
    "            \"patience\": [5, 10],\n",
    "            \"min_delta\": [0.001],\n",
    "            \"epochs\": [30, 50],\n",
    "            \"learning_rate\": [0.001, 0.01],\n",
    "            \"layers\": [\n",
    "                {\n",
    "                    \"name\": 'DenseBatchNormalizationDropoutTuner',\n",
    "                    \"dropout_rate\": 0.5,\n",
    "                    \"start_units\": 16,\n",
    "                    \"list_num_layers\": [1,2,3,4,5],\n",
    "                },\n",
    "                {\n",
    "                    \"name\": 'DenseBatchNormalizationTuner',\n",
    "                    \"start_units\": 8,\n",
    "                    \"list_num_layers\": [1,2,3,4,5],\n",
    "\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        ```\n",
    "        Khi đó tập trung xử lí key 'layers' để đưa **param_dict** về dạng dict như này: <br>\n",
    "        ```\n",
    "        param_dict_transformed = {\n",
    "            'patience': [5, 10],\n",
    "            'min_delta': [0.001],\n",
    "            'epochs': [30, 50],\n",
    "            'learning_rate': [0.001, 0.01],\n",
    "            'layer0__name': ['DenseBatchNormalizationDropoutTuner'],\n",
    "            'layer0__dropout_rate': [0.5],\n",
    "            'layer0__start_units': [16],\n",
    "            'layer0__num_layers': [1, 2, 3, 4, 5],\n",
    "            'layer1__name': ['DenseBatchNormalizationTuner'],\n",
    "            'layer1__start_units': [8],\n",
    "            'layer1__num_layers': [1, 2, 3, 4, 5]\n",
    "        }\n",
    "        ```\n",
    "        Sau đó lấy ngẫu nhiên **num_models** tập tham số từ **param_dict_transformed**\n",
    "\n",
    "        Args:\n",
    "            param_dict (_type_): dict\n",
    "            num_models (_type_): số lượng tập tham số cần lấy\n",
    "        \"\"\"\n",
    "        self.param_dict = param_dict\n",
    "        self.num_models = num_models\n",
    "\n",
    "    def next(self):\n",
    "        # Loại bỏ key\n",
    "        list_layers = self.param_dict.pop(\"layers\")\n",
    "\n",
    "        # Thêm tiền tố layer vào mỗi key trong list_layers\n",
    "        list_layers = [\n",
    "            self.add_layer_text_to_key(layer, i) for i, layer in enumerate(list_layers)\n",
    "        ]\n",
    "\n",
    "        # Tạo list_layers mới\n",
    "        list_layers_keys = list(\n",
    "            itertools.chain(*[list(item.keys()) for item in list_layers])\n",
    "        )\n",
    "        list_layers_values = list(\n",
    "            itertools.chain(*[list(item.values()) for item in list_layers])\n",
    "        )\n",
    "        list_layers = dict(zip(list_layers_keys, list_layers_values))\n",
    "\n",
    "        # Tổng hợp tạo ra param_dict\n",
    "        param_dict_keys = list(self.param_dict.keys()) + list(list_layers.keys())\n",
    "        param_dict_values = list(self.param_dict.values()) + list(list_layers.values())\n",
    "        param_dict_values = [\n",
    "            item if isinstance(item, list) else [item] for item in param_dict_values\n",
    "        ]\n",
    "\n",
    "        param_dict = dict(zip(param_dict_keys, param_dict_values))\n",
    "\n",
    "        return param_dict\n",
    "\n",
    "    def add_layer_text_to_key(self, a, i):\n",
    "        if not a: \n",
    "            a[f\"layer{i}__none\"] = None\n",
    "            return a\n",
    "\n",
    "        a_keys = [f\"layer{i}__{key}\" for key in a.keys()]\n",
    "        a = dict(zip(a_keys, a.values()))\n",
    "        return a\n",
    "    \n",
    "\n",
    "        class LayerCreator:\n",
    "            \"\"\"Create layer từ param và text đại diện cho layer đó <br>\n",
    "\n",
    "            Examples:\n",
    "            ```\n",
    "            param = {\n",
    "                'patience': 10,\n",
    "                'min_delta': 0.001,\n",
    "                'learning_rate': 0.01,\n",
    "                'layer1__start_units': 8,\n",
    "                'layer1__num_layers': 4,\n",
    "                'layer1__name': 'DenseBatchNormalizationTuner',\n",
    "                'layer0__start_units': 16,\n",
    "                'layer0__num_layers': 5,\n",
    "                'layer0__name': 'DenseBatchNormalizationDropoutTuner',\n",
    "                'layer0__dropout_rate': 0.5,\n",
    "                'epochs': 30\n",
    "            }\n",
    "            layer_text = 'layer0'\n",
    "\n",
    "            ```\n",
    "            Khi đó tạo layer từ các key có chứa 'layer0' là: start_units, num_layers, name, dropout_rate\n",
    "\n",
    "            Args:\n",
    "                param (_type_): dict\n",
    "                layer_text (_type_): text thể hiện cho layer cần tạo\n",
    "            \"\"\"\n",
    "\n",
    "            def __init__(self, param, layer_text):\n",
    "                self.param = param\n",
    "                self.layer_text = layer_text\n",
    "\n",
    "            def next(self):\n",
    "                # Kiểm tra có phải PassThroughLayer\n",
    "                if self.is_PassThroughLayer(): \n",
    "                    return tf_myclasses.PassThroughLayer()\n",
    "\n",
    "                # Get param ứng với layer_text\n",
    "                keys = pd.Series(self.param.keys())\n",
    "                values = pd.Series(self.param.values())\n",
    "                keys = keys[keys.str.startswith(self.layer_text)]\n",
    "                values = values[keys.str.startswith(self.layer_text)]\n",
    "\n",
    "                keys = keys.apply(self.get_param_name)\n",
    "                layer_param = dict(zip(keys, values))\n",
    "\n",
    "                # Tạo class\n",
    "                class_name = layer_param.pop(\"name\")\n",
    "                ClassName = globals()[class_name]\n",
    "\n",
    "                # Tạo object\n",
    "                layer = ClassName(**layer_param)\n",
    "                return layer\n",
    "\n",
    "            def get_param_name(self, key):\n",
    "                parts = key.split(\"__\", 1)\n",
    "                return parts[1]\n",
    "            \n",
    "            def is_PassThroughLayer(self): \n",
    "                keys = pd.Series(self.param.keys())\n",
    "                keys = keys[keys.str.startswith(self.layer_text)]\n",
    "                return keys.iloc[0] == f\"{self.layer_text}__none\"\n",
    "\n",
    "\n",
    "a = ListParamCreator(param_dict, 10).next()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834b2fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rỗng rồi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layer1': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello = {}\n",
    "\n",
    "if not hello: \n",
    "    print(\"Rỗng rồi\")\n",
    "\n",
    "def add_layer_text_to_key(a, i):\n",
    "    if not a: \n",
    "        a[f\"layer{i}\"] = None\n",
    "        return a\n",
    "\n",
    "    a_keys = [f\"layer{i}__{key}\" for key in a.keys()]\n",
    "    a = dict(zip(a_keys, a.values()))\n",
    "    return a\n",
    "\n",
    "b = add_layer_text_to_key(hello, 1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4643d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_sum(a, b): \n",
    "    return a+b\n",
    "\n",
    "def calculate_subtraction(a,b):\n",
    "    return a-b\n",
    "\n",
    "def demo_funcs(a, b, c, funcs):\n",
    "    d = funcs(a, b)\n",
    "    return d + c\n",
    "\n",
    "demo_funcs(1,1,1, calculate_subtraction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
